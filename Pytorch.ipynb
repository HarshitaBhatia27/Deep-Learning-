{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLdeZFylF0Horyy9dtvAJx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshitaBhatia27/Deep-Learning-/blob/main/Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch is an open source ML framework used for developing and training DL models.While Tensorflow focuses more on static computation graphs, pytorch emphasizes dynamic computation graphs."
      ],
      "metadata": {
        "id": "7AGyNbudQ56U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N_ySJMe6Qpeh"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors\n",
        "\n",
        "--> pytorch is a library for processing tensors. A tensor is a number, vector, matrix or any n-D array"
      ],
      "metadata": {
        "id": "lKUmYJOURXME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1= torch.tensor(4.)\n",
        "t1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_5E7I6oRS4z",
        "outputId": "4d3012ff-3640-45a4-c322-e95bf8fcfc98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfceJVl9Rjmm",
        "outputId": "fa4cc508-d23f-4305-bb98-7e6a34450e36"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2= torch.tensor([1.,2.,3.,4.]) #vector\n",
        "t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntIJZ2BGRmBO",
        "outputId": "c66bf63f-32fd-4b04-cbe3-2521db5a59cd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t3= torch.tensor([[5.,6.],[7,8],[9,10]]) #matrix\n",
        "t3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eFdE_sqRsed",
        "outputId": "faaad786-e964-4787-e7fd-905f2e02617d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t3.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rojyCnBaR0n7",
        "outputId": "13d95545-b15b-4159-f0cf-d96227b4b5bf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t4= torch.tensor([[[11,12,13],[13,14,15]],[[15,16,17],[17,18,20]]])  #3-D array\n",
        "t4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUPfgAorR3lK",
        "outputId": "57d56e95-70f4-4c74-ba4a-c740757a7ed5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[11, 12, 13],\n",
              "         [13, 14, 15]],\n",
              "\n",
              "        [[15, 16, 17],\n",
              "         [17, 18, 20]]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors can have any no. of dimensions and diff lengths along each dimension. We can inspect the length along each dimension using .shape property"
      ],
      "metadata": {
        "id": "UEWbputvSUVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(t1)\n",
        "t1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX7iWQcKSGDS",
        "outputId": "9265f720-0c6c-4aff-85b1-a3da44c852d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t2)\n",
        "t2.shape\n",
        "#shape is the no. of elements"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghfsWga-SQYr",
        "outputId": "a1158e79-70c8-4c45-ed73-060b49683fa9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4.])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t3)\n",
        "t3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGzeF3YKShDc",
        "outputId": "bfebdba1-ef1a-4fcd-c52e-4715456c8fef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5.,  6.],\n",
            "        [ 7.,  8.],\n",
            "        [ 9., 10.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t4)\n",
        "t4.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEIdFA59SjMx",
        "outputId": "38560973-ac10-4183-8b2e-c77291301d70"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[11, 12, 13],\n",
            "         [13, 14, 15]],\n",
            "\n",
            "        [[15, 16, 17],\n",
            "         [17, 18, 20]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#matrix\n",
        "\n",
        "t5 = torch.tensor([[5.,6.,7.],[7,8],[9,10]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "G3Crb53ASqCB",
        "outputId": "7c06184d-e79b-4e23-cb9a-3b3d853f113a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-d46d818087d9>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mt5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: expected sequence of length 3 at dim 1 (got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: It is not possible to create tensors with an improper shape in pytorch."
      ],
      "metadata": {
        "id": "0TkY19IUTMUZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor operations and gradients"
      ],
      "metadata": {
        "id": "fWTOsTmJTTh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=torch.tensor(3.)\n",
        "w= torch.tensor(4., requires_grad=True)\n",
        "b=torch.tensor(5.,requires_grad=True) #requires_grad is True meaning that at time of back propagation their gradient will be calculated\n",
        "x,w,b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JypYBBHhTKTs",
        "outputId": "b5bbe253-e4f9-4ed9-8a24-e0eae75bed87"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= w*x+b\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH-caT6ZTlkh",
        "outputId": "3f60a0a2-eaab-4ab7-aed9-95fddb082b78"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward() #compute derivates"
      ],
      "metadata": {
        "id": "j7ed6qC6T8H3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5WOnmVSU2D2",
        "outputId": "7c6e03eb-1fea-4a8b-99aa-c972e8800d17"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#display gradient\n",
        "print('dy/dx', x.grad)\n",
        "print('dy/dw', w.grad)\n",
        "print('dy/db', b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX46-SG0UHkv",
        "outputId": "ff6e451c-ebf0-46e5-c4ad-acab5fee5e7d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dx None\n",
            "dy/dw tensor(3.)\n",
            "dy/db tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For x, the gradient was not true so it showed none but for other 2 the gradients are calculated."
      ],
      "metadata": {
        "id": "_jqowp7oUiUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor Functions**"
      ],
      "metadata": {
        "id": "2EkAgMoJU-wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t6= torch.full((3,2),42) #create tensor with a fixed value for every element\n",
        "t6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wbVb-dVUgRn",
        "outputId": "a2b4b35d-d705-43ca-b581-0bafca5044ba"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[42, 42],\n",
              "        [42, 42],\n",
              "        [42, 42]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdBVRbFwVFWa",
        "outputId": "d321bbda-9442-4e17-989a-3639e4653c6c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4nPwqjFVKug",
        "outputId": "890c5442-ab19-4357-8ed4-1e03fa2c4ab3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[42, 42],\n",
              "        [42, 42],\n",
              "        [42, 42]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#concat tensors with compatible shape\n",
        "t7= torch.cat((t3,t6),axis=0)  #axis=1 is col wise, 0 is row wise\n",
        "t7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKQrVgI3VLuw",
        "outputId": "35b52b69-2a61-4444-e7e6-4f762704f287"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.],\n",
              "        [42., 42.],\n",
              "        [42., 42.],\n",
              "        [42., 42.]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t8=torch.sin(t7) #sin of each element\n",
        "t8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffhtVg0aVQNO",
        "outputId": "2b6ebbf8-3a3d-4c17-9452-610babd22f26"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9589, -0.2794],\n",
              "        [ 0.6570,  0.9894],\n",
              "        [ 0.4121, -0.5440],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t9=t8.reshape(3,2,2) #3-D\n",
        "t9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_b8YRquVb7i",
        "outputId": "0dd4376f-5571-4437-8cad-b91322f50ccf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.9589, -0.2794],\n",
              "         [ 0.6570,  0.9894]],\n",
              "\n",
              "        [[ 0.4121, -0.5440],\n",
              "         [-0.9165, -0.9165]],\n",
              "\n",
              "        [[-0.9165, -0.9165],\n",
              "         [-0.9165, -0.9165]]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interoperability with Numpy"
      ],
      "metadata": {
        "id": "EgKeT_6VWE8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x= np.array([[1,2],[3,4]])\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqgPDo8gVqem",
        "outputId": "594aef34-e328-4bd6-d71a-539615b9fd27"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y= torch.from_numpy(x) #convert numpy array to tensor\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRRHw1mxWN7l",
        "outputId": "4b6d5a66-417a-4420-9c65-f7f3048f0586"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.dtype, y.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6V1_5jqWSTy",
        "outputId": "6d43bc9e-dca1-4875-b9e0-303f182f46fa"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('int64'), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensor to numpy array is converted using .numpy method\n",
        "z=y.numpy()\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr8Zl0EFW7K8",
        "outputId": "9833799a-7b5c-431c-cbfe-0ae6d320cf38"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear-regression using pytorch"
      ],
      "metadata": {
        "id": "lRJBSBJJXart"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making train data\n",
        "#(temp,rainfall,humidity)\n",
        "inputs= np.array([[73,67,43],[91,88,64],[87,134,58],[102,43,37],[69,96,70]],dtype='float32')"
      ],
      "metadata": {
        "id": "tcQR6GF-XDDE"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#targets (apples,oranges)\n",
        "target=np.array([[56,70],[81,101],[119,133],[22,37],[103,119]],dtype='float32')"
      ],
      "metadata": {
        "id": "xbk4OmWqXuDs"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert input and target to tensor\n",
        "inputs=torch.from_numpy(inputs)\n",
        "target=torch.from_numpy(target)\n",
        "print(inputs,\"\\n\")\n",
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA5H0iSkX9wF",
        "outputId": "40ae2d1f-c1ef-40bd-c426-d12e53c0355b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]]) \n",
            "\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#weights and biases\n",
        "w= torch.randn(2,3,requires_grad=True)\n",
        "b= torch.randn(2,requires_grad=True)\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9zkW7VWYLhy",
        "outputId": "10570ded-3744-4833-d91a-26718c206db0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6510,  0.1770,  1.8137],\n",
            "        [ 1.4961,  0.9741,  0.2911]], requires_grad=True)\n",
            "tensor([ 1.5542, -1.1863], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model\n",
        "def model(x):\n",
        "  return x @ w.t()+b\n",
        "\n",
        "# x is multiplied with transpose of w"
      ],
      "metadata": {
        "id": "qmEXMp_7Yjm8"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PREDICTTED\n",
        "preds= model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR_zgEFfYynt",
        "outputId": "9d8f6460-d018-4a3b-f51e-dc3c0f3976fa"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 43.8809, 185.8123],\n",
            "        [ 73.9683, 239.3115],\n",
            "        [ 73.8336, 276.3887],\n",
            "        [  9.8701, 204.0754],\n",
            "        [100.5894, 215.9359]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#actual\n",
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjJa6LRHZeSp",
        "outputId": "beb2905e-096a-4f05-8717-23715126a11d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loss function mse\n",
        "def MSE(actual,target):\n",
        "  diff= actual-target\n",
        "  return torch.sum(diff * diff)/diff.numel()\n",
        "\n",
        "#This finalizes the calculation of the mean squared error (MSE) by dividing the sum of squared differences by the total number of elements.\n",
        "#This yields the average squared difference between corresponding elements in the tensors, which is a measure of how much the tensors differ on average."
      ],
      "metadata": {
        "id": "wqrWcJ1nZiqS"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#error\n",
        "loss=MSE(target,preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbhQx6olZzWG",
        "outputId": "6ea6cc12-b5d3-4523-cd75-b8e682e90307"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(9280.2939, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "\n",
        "print(w.grad,\"\\n\")\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uyh-HRaUaL0Y",
        "outputId": "4df99212-ff68-4bd9-ac6b-d5bbff21b3b2"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1371.5281, -1647.2146,  -841.6702],\n",
            "        [11449.1484, 11127.0049,  7023.1431]]) \n",
            "\n",
            "tensor([-15.7715, 132.3048])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adjust weight and reset grad\n",
        "with torch.no_grad():\n",
        "  w -= w.grad* 1e-5  #1e-5 taken as learning rate\n",
        "  b -= b.grad * 1e-5\n",
        "  w.grad.zero_()\n",
        "  b.grad.zero_()"
      ],
      "metadata": {
        "id": "A3KrNmBGaagY"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llso030JasvI",
        "outputId": "b5a99917-dcec-4ed1-c117-ad5d70aee13f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6373,  0.1935,  1.8221],\n",
            "        [ 1.3816,  0.8628,  0.2209]], requires_grad=True)\n",
            "tensor([ 1.5544, -1.1876], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds=model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLV1rHrEavi3",
        "outputId": "64159931-ae2b-4ade-bd3e-011539610592"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 46.3478, 166.9781],\n",
            "        [ 77.2048, 214.6049],\n",
            "        [ 77.7224, 247.4430],\n",
            "        [ 12.2889, 185.0128],\n",
            "        [103.7064, 192.4365]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=MSE(target,preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utPZZ0lKa-Al",
        "outputId": "f37ea965-5962-4136-d3aa-e0c9b78d2c13"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(6461.4951, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trainig for multiple epochs\n",
        "for i in range(400):\n",
        "  preds= model(inputs)\n",
        "  loss=MSE(target,preds)\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    w -= w.grad* 1e-5  #1e-5 taken as learning rate\n",
        "    b -= b.grad * 1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "  print(f\"Epochs({i}/{400}) & Loss {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hamAexcrbA3D",
        "outputId": "3621bb9e-7820-45ca-e35d-8505fd40aeea"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs(0/400) & Loss 65.5509262084961\n",
            "Epochs(1/400) & Loss 65.39494323730469\n",
            "Epochs(2/400) & Loss 65.2396240234375\n",
            "Epochs(3/400) & Loss 65.08502960205078\n",
            "Epochs(4/400) & Loss 64.93115234375\n",
            "Epochs(5/400) & Loss 64.77799987792969\n",
            "Epochs(6/400) & Loss 64.6255874633789\n",
            "Epochs(7/400) & Loss 64.47380065917969\n",
            "Epochs(8/400) & Loss 64.32274627685547\n",
            "Epochs(9/400) & Loss 64.17237091064453\n",
            "Epochs(10/400) & Loss 64.02271270751953\n",
            "Epochs(11/400) & Loss 63.873626708984375\n",
            "Epochs(12/400) & Loss 63.72522735595703\n",
            "Epochs(13/400) & Loss 63.577545166015625\n",
            "Epochs(14/400) & Loss 63.430519104003906\n",
            "Epochs(15/400) & Loss 63.284034729003906\n",
            "Epochs(16/400) & Loss 63.138282775878906\n",
            "Epochs(17/400) & Loss 62.99311065673828\n",
            "Epochs(18/400) & Loss 62.84864044189453\n",
            "Epochs(19/400) & Loss 62.7047233581543\n",
            "Epochs(20/400) & Loss 62.56147003173828\n",
            "Epochs(21/400) & Loss 62.41878128051758\n",
            "Epochs(22/400) & Loss 62.276756286621094\n",
            "Epochs(23/400) & Loss 62.13530349731445\n",
            "Epochs(24/400) & Loss 61.994407653808594\n",
            "Epochs(25/400) & Loss 61.85413360595703\n",
            "Epochs(26/400) & Loss 61.71443557739258\n",
            "Epochs(27/400) & Loss 61.575340270996094\n",
            "Epochs(28/400) & Loss 61.43680953979492\n",
            "Epochs(29/400) & Loss 61.29883575439453\n",
            "Epochs(30/400) & Loss 61.16144561767578\n",
            "Epochs(31/400) & Loss 61.02461624145508\n",
            "Epochs(32/400) & Loss 60.888328552246094\n",
            "Epochs(33/400) & Loss 60.752586364746094\n",
            "Epochs(34/400) & Loss 60.61738204956055\n",
            "Epochs(35/400) & Loss 60.48278045654297\n",
            "Epochs(36/400) & Loss 60.34865188598633\n",
            "Epochs(37/400) & Loss 60.215057373046875\n",
            "Epochs(38/400) & Loss 60.081993103027344\n",
            "Epochs(39/400) & Loss 59.94944381713867\n",
            "Epochs(40/400) & Loss 59.81743621826172\n",
            "Epochs(41/400) & Loss 59.6859130859375\n",
            "Epochs(42/400) & Loss 59.554969787597656\n",
            "Epochs(43/400) & Loss 59.42445755004883\n",
            "Epochs(44/400) & Loss 59.294464111328125\n",
            "Epochs(45/400) & Loss 59.16498947143555\n",
            "Epochs(46/400) & Loss 59.03593826293945\n",
            "Epochs(47/400) & Loss 58.90742111206055\n",
            "Epochs(48/400) & Loss 58.7794189453125\n",
            "Epochs(49/400) & Loss 58.65190887451172\n",
            "Epochs(50/400) & Loss 58.52479934692383\n",
            "Epochs(51/400) & Loss 58.3982048034668\n",
            "Epochs(52/400) & Loss 58.272071838378906\n",
            "Epochs(53/400) & Loss 58.146339416503906\n",
            "Epochs(54/400) & Loss 58.021156311035156\n",
            "Epochs(55/400) & Loss 57.896400451660156\n",
            "Epochs(56/400) & Loss 57.772125244140625\n",
            "Epochs(57/400) & Loss 57.6483039855957\n",
            "Epochs(58/400) & Loss 57.52490234375\n",
            "Epochs(59/400) & Loss 57.401893615722656\n",
            "Epochs(60/400) & Loss 57.27935791015625\n",
            "Epochs(61/400) & Loss 57.15727615356445\n",
            "Epochs(62/400) & Loss 57.03565216064453\n",
            "Epochs(63/400) & Loss 56.91440963745117\n",
            "Epochs(64/400) & Loss 56.7935905456543\n",
            "Epochs(65/400) & Loss 56.673240661621094\n",
            "Epochs(66/400) & Loss 56.553306579589844\n",
            "Epochs(67/400) & Loss 56.43378448486328\n",
            "Epochs(68/400) & Loss 56.31462478637695\n",
            "Epochs(69/400) & Loss 56.19588088989258\n",
            "Epochs(70/400) & Loss 56.07757568359375\n",
            "Epochs(71/400) & Loss 55.959678649902344\n",
            "Epochs(72/400) & Loss 55.842140197753906\n",
            "Epochs(73/400) & Loss 55.725074768066406\n",
            "Epochs(74/400) & Loss 55.60831832885742\n",
            "Epochs(75/400) & Loss 55.49198532104492\n",
            "Epochs(76/400) & Loss 55.37607955932617\n",
            "Epochs(77/400) & Loss 55.260498046875\n",
            "Epochs(78/400) & Loss 55.14532470703125\n",
            "Epochs(79/400) & Loss 55.030540466308594\n",
            "Epochs(80/400) & Loss 54.9161262512207\n",
            "Epochs(81/400) & Loss 54.802040100097656\n",
            "Epochs(82/400) & Loss 54.68840789794922\n",
            "Epochs(83/400) & Loss 54.575111389160156\n",
            "Epochs(84/400) & Loss 54.462188720703125\n",
            "Epochs(85/400) & Loss 54.34955596923828\n",
            "Epochs(86/400) & Loss 54.23738479614258\n",
            "Epochs(87/400) & Loss 54.125511169433594\n",
            "Epochs(88/400) & Loss 54.01401901245117\n",
            "Epochs(89/400) & Loss 53.902870178222656\n",
            "Epochs(90/400) & Loss 53.792152404785156\n",
            "Epochs(91/400) & Loss 53.68164825439453\n",
            "Epochs(92/400) & Loss 53.5715446472168\n",
            "Epochs(93/400) & Loss 53.46178436279297\n",
            "Epochs(94/400) & Loss 53.352378845214844\n",
            "Epochs(95/400) & Loss 53.2432746887207\n",
            "Epochs(96/400) & Loss 53.13456344604492\n",
            "Epochs(97/400) & Loss 53.026161193847656\n",
            "Epochs(98/400) & Loss 52.91807174682617\n",
            "Epochs(99/400) & Loss 52.810333251953125\n",
            "Epochs(100/400) & Loss 52.702880859375\n",
            "Epochs(101/400) & Loss 52.59581756591797\n",
            "Epochs(102/400) & Loss 52.489051818847656\n",
            "Epochs(103/400) & Loss 52.38258743286133\n",
            "Epochs(104/400) & Loss 52.27643966674805\n",
            "Epochs(105/400) & Loss 52.17060089111328\n",
            "Epochs(106/400) & Loss 52.065101623535156\n",
            "Epochs(107/400) & Loss 51.959922790527344\n",
            "Epochs(108/400) & Loss 51.855064392089844\n",
            "Epochs(109/400) & Loss 51.7504768371582\n",
            "Epochs(110/400) & Loss 51.6462287902832\n",
            "Epochs(111/400) & Loss 51.54227828979492\n",
            "Epochs(112/400) & Loss 51.43865203857422\n",
            "Epochs(113/400) & Loss 51.335289001464844\n",
            "Epochs(114/400) & Loss 51.23217010498047\n",
            "Epochs(115/400) & Loss 51.12940216064453\n",
            "Epochs(116/400) & Loss 51.026878356933594\n",
            "Epochs(117/400) & Loss 50.92475128173828\n",
            "Epochs(118/400) & Loss 50.82289505004883\n",
            "Epochs(119/400) & Loss 50.72127914428711\n",
            "Epochs(120/400) & Loss 50.62000274658203\n",
            "Epochs(121/400) & Loss 50.51899337768555\n",
            "Epochs(122/400) & Loss 50.41822052001953\n",
            "Epochs(123/400) & Loss 50.31775665283203\n",
            "Epochs(124/400) & Loss 50.217567443847656\n",
            "Epochs(125/400) & Loss 50.11769485473633\n",
            "Epochs(126/400) & Loss 50.0180549621582\n",
            "Epochs(127/400) & Loss 49.91870880126953\n",
            "Epochs(128/400) & Loss 49.819698333740234\n",
            "Epochs(129/400) & Loss 49.720909118652344\n",
            "Epochs(130/400) & Loss 49.62235641479492\n",
            "Epochs(131/400) & Loss 49.52410125732422\n",
            "Epochs(132/400) & Loss 49.42608642578125\n",
            "Epochs(133/400) & Loss 49.32834243774414\n",
            "Epochs(134/400) & Loss 49.23088836669922\n",
            "Epochs(135/400) & Loss 49.13369369506836\n",
            "Epochs(136/400) & Loss 49.036705017089844\n",
            "Epochs(137/400) & Loss 48.940059661865234\n",
            "Epochs(138/400) & Loss 48.843666076660156\n",
            "Epochs(139/400) & Loss 48.74748992919922\n",
            "Epochs(140/400) & Loss 48.65156173706055\n",
            "Epochs(141/400) & Loss 48.55588150024414\n",
            "Epochs(142/400) & Loss 48.46050262451172\n",
            "Epochs(143/400) & Loss 48.36534118652344\n",
            "Epochs(144/400) & Loss 48.27047348022461\n",
            "Epochs(145/400) & Loss 48.1757698059082\n",
            "Epochs(146/400) & Loss 48.081390380859375\n",
            "Epochs(147/400) & Loss 47.987274169921875\n",
            "Epochs(148/400) & Loss 47.893280029296875\n",
            "Epochs(149/400) & Loss 47.799644470214844\n",
            "Epochs(150/400) & Loss 47.70621109008789\n",
            "Epochs(151/400) & Loss 47.6130256652832\n",
            "Epochs(152/400) & Loss 47.52005386352539\n",
            "Epochs(153/400) & Loss 47.427345275878906\n",
            "Epochs(154/400) & Loss 47.3348274230957\n",
            "Epochs(155/400) & Loss 47.24259948730469\n",
            "Epochs(156/400) & Loss 47.150596618652344\n",
            "Epochs(157/400) & Loss 47.0588264465332\n",
            "Epochs(158/400) & Loss 46.96728515625\n",
            "Epochs(159/400) & Loss 46.8759765625\n",
            "Epochs(160/400) & Loss 46.78491973876953\n",
            "Epochs(161/400) & Loss 46.69401168823242\n",
            "Epochs(162/400) & Loss 46.60341262817383\n",
            "Epochs(163/400) & Loss 46.512977600097656\n",
            "Epochs(164/400) & Loss 46.422813415527344\n",
            "Epochs(165/400) & Loss 46.33283233642578\n",
            "Epochs(166/400) & Loss 46.24314880371094\n",
            "Epochs(167/400) & Loss 46.15366744995117\n",
            "Epochs(168/400) & Loss 46.064334869384766\n",
            "Epochs(169/400) & Loss 45.97520065307617\n",
            "Epochs(170/400) & Loss 45.88634490966797\n",
            "Epochs(171/400) & Loss 45.79772186279297\n",
            "Epochs(172/400) & Loss 45.709354400634766\n",
            "Epochs(173/400) & Loss 45.621131896972656\n",
            "Epochs(174/400) & Loss 45.53314971923828\n",
            "Epochs(175/400) & Loss 45.44538116455078\n",
            "Epochs(176/400) & Loss 45.357749938964844\n",
            "Epochs(177/400) & Loss 45.270423889160156\n",
            "Epochs(178/400) & Loss 45.183250427246094\n",
            "Epochs(179/400) & Loss 45.09633255004883\n",
            "Epochs(180/400) & Loss 45.00962829589844\n",
            "Epochs(181/400) & Loss 44.92301940917969\n",
            "Epochs(182/400) & Loss 44.83668518066406\n",
            "Epochs(183/400) & Loss 44.75061798095703\n",
            "Epochs(184/400) & Loss 44.66471481323242\n",
            "Epochs(185/400) & Loss 44.57898712158203\n",
            "Epochs(186/400) & Loss 44.493499755859375\n",
            "Epochs(187/400) & Loss 44.408180236816406\n",
            "Epochs(188/400) & Loss 44.32305908203125\n",
            "Epochs(189/400) & Loss 44.238182067871094\n",
            "Epochs(190/400) & Loss 44.15347671508789\n",
            "Epochs(191/400) & Loss 44.068946838378906\n",
            "Epochs(192/400) & Loss 43.98467254638672\n",
            "Epochs(193/400) & Loss 43.90052032470703\n",
            "Epochs(194/400) & Loss 43.816612243652344\n",
            "Epochs(195/400) & Loss 43.73288345336914\n",
            "Epochs(196/400) & Loss 43.64929962158203\n",
            "Epochs(197/400) & Loss 43.56599426269531\n",
            "Epochs(198/400) & Loss 43.48289489746094\n",
            "Epochs(199/400) & Loss 43.399925231933594\n",
            "Epochs(200/400) & Loss 43.31714630126953\n",
            "Epochs(201/400) & Loss 43.23451614379883\n",
            "Epochs(202/400) & Loss 43.152191162109375\n",
            "Epochs(203/400) & Loss 43.07002258300781\n",
            "Epochs(204/400) & Loss 42.987998962402344\n",
            "Epochs(205/400) & Loss 42.906150817871094\n",
            "Epochs(206/400) & Loss 42.82451629638672\n",
            "Epochs(207/400) & Loss 42.74301528930664\n",
            "Epochs(208/400) & Loss 42.66179275512695\n",
            "Epochs(209/400) & Loss 42.58070755004883\n",
            "Epochs(210/400) & Loss 42.49977111816406\n",
            "Epochs(211/400) & Loss 42.41904067993164\n",
            "Epochs(212/400) & Loss 42.33849334716797\n",
            "Epochs(213/400) & Loss 42.258155822753906\n",
            "Epochs(214/400) & Loss 42.17795944213867\n",
            "Epochs(215/400) & Loss 42.09791564941406\n",
            "Epochs(216/400) & Loss 42.01811981201172\n",
            "Epochs(217/400) & Loss 41.93842697143555\n",
            "Epochs(218/400) & Loss 41.858985900878906\n",
            "Epochs(219/400) & Loss 41.77969741821289\n",
            "Epochs(220/400) & Loss 41.700557708740234\n",
            "Epochs(221/400) & Loss 41.62163162231445\n",
            "Epochs(222/400) & Loss 41.542869567871094\n",
            "Epochs(223/400) & Loss 41.464256286621094\n",
            "Epochs(224/400) & Loss 41.38585662841797\n",
            "Epochs(225/400) & Loss 41.30758285522461\n",
            "Epochs(226/400) & Loss 41.2295036315918\n",
            "Epochs(227/400) & Loss 41.15156173706055\n",
            "Epochs(228/400) & Loss 41.07380676269531\n",
            "Epochs(229/400) & Loss 40.99624252319336\n",
            "Epochs(230/400) & Loss 40.91889190673828\n",
            "Epochs(231/400) & Loss 40.84163284301758\n",
            "Epochs(232/400) & Loss 40.76455307006836\n",
            "Epochs(233/400) & Loss 40.68767547607422\n",
            "Epochs(234/400) & Loss 40.61091613769531\n",
            "Epochs(235/400) & Loss 40.534324645996094\n",
            "Epochs(236/400) & Loss 40.45793151855469\n",
            "Epochs(237/400) & Loss 40.3817024230957\n",
            "Epochs(238/400) & Loss 40.305633544921875\n",
            "Epochs(239/400) & Loss 40.229679107666016\n",
            "Epochs(240/400) & Loss 40.153892517089844\n",
            "Epochs(241/400) & Loss 40.078407287597656\n",
            "Epochs(242/400) & Loss 40.00292205810547\n",
            "Epochs(243/400) & Loss 39.92768859863281\n",
            "Epochs(244/400) & Loss 39.85258483886719\n",
            "Epochs(245/400) & Loss 39.777652740478516\n",
            "Epochs(246/400) & Loss 39.70288848876953\n",
            "Epochs(247/400) & Loss 39.62822723388672\n",
            "Epochs(248/400) & Loss 39.55376434326172\n",
            "Epochs(249/400) & Loss 39.479454040527344\n",
            "Epochs(250/400) & Loss 39.405311584472656\n",
            "Epochs(251/400) & Loss 39.33134460449219\n",
            "Epochs(252/400) & Loss 39.257476806640625\n",
            "Epochs(253/400) & Loss 39.183815002441406\n",
            "Epochs(254/400) & Loss 39.11030578613281\n",
            "Epochs(255/400) & Loss 39.03690719604492\n",
            "Epochs(256/400) & Loss 38.963722229003906\n",
            "Epochs(257/400) & Loss 38.890625\n",
            "Epochs(258/400) & Loss 38.817710876464844\n",
            "Epochs(259/400) & Loss 38.74494171142578\n",
            "Epochs(260/400) & Loss 38.672359466552734\n",
            "Epochs(261/400) & Loss 38.599952697753906\n",
            "Epochs(262/400) & Loss 38.52764129638672\n",
            "Epochs(263/400) & Loss 38.45548629760742\n",
            "Epochs(264/400) & Loss 38.38346862792969\n",
            "Epochs(265/400) & Loss 38.311622619628906\n",
            "Epochs(266/400) & Loss 38.23992156982422\n",
            "Epochs(267/400) & Loss 38.168338775634766\n",
            "Epochs(268/400) & Loss 38.09695816040039\n",
            "Epochs(269/400) & Loss 38.02567672729492\n",
            "Epochs(270/400) & Loss 37.95457077026367\n",
            "Epochs(271/400) & Loss 37.883644104003906\n",
            "Epochs(272/400) & Loss 37.812801361083984\n",
            "Epochs(273/400) & Loss 37.74214553833008\n",
            "Epochs(274/400) & Loss 37.67166519165039\n",
            "Epochs(275/400) & Loss 37.60123825073242\n",
            "Epochs(276/400) & Loss 37.531005859375\n",
            "Epochs(277/400) & Loss 37.460914611816406\n",
            "Epochs(278/400) & Loss 37.390953063964844\n",
            "Epochs(279/400) & Loss 37.321189880371094\n",
            "Epochs(280/400) & Loss 37.25151824951172\n",
            "Epochs(281/400) & Loss 37.18196487426758\n",
            "Epochs(282/400) & Loss 37.112648010253906\n",
            "Epochs(283/400) & Loss 37.04340744018555\n",
            "Epochs(284/400) & Loss 36.97431182861328\n",
            "Epochs(285/400) & Loss 36.90538787841797\n",
            "Epochs(286/400) & Loss 36.836570739746094\n",
            "Epochs(287/400) & Loss 36.76789474487305\n",
            "Epochs(288/400) & Loss 36.699378967285156\n",
            "Epochs(289/400) & Loss 36.63098907470703\n",
            "Epochs(290/400) & Loss 36.56275177001953\n",
            "Epochs(291/400) & Loss 36.49464797973633\n",
            "Epochs(292/400) & Loss 36.426673889160156\n",
            "Epochs(293/400) & Loss 36.35880661010742\n",
            "Epochs(294/400) & Loss 36.29111862182617\n",
            "Epochs(295/400) & Loss 36.22355270385742\n",
            "Epochs(296/400) & Loss 36.156089782714844\n",
            "Epochs(297/400) & Loss 36.0888671875\n",
            "Epochs(298/400) & Loss 36.02165985107422\n",
            "Epochs(299/400) & Loss 35.954681396484375\n",
            "Epochs(300/400) & Loss 35.887786865234375\n",
            "Epochs(301/400) & Loss 35.8210334777832\n",
            "Epochs(302/400) & Loss 35.754417419433594\n",
            "Epochs(303/400) & Loss 35.68798828125\n",
            "Epochs(304/400) & Loss 35.62163543701172\n",
            "Epochs(305/400) & Loss 35.55537796020508\n",
            "Epochs(306/400) & Loss 35.48930740356445\n",
            "Epochs(307/400) & Loss 35.423362731933594\n",
            "Epochs(308/400) & Loss 35.35758590698242\n",
            "Epochs(309/400) & Loss 35.29188537597656\n",
            "Epochs(310/400) & Loss 35.22629928588867\n",
            "Epochs(311/400) & Loss 35.160850524902344\n",
            "Epochs(312/400) & Loss 35.095584869384766\n",
            "Epochs(313/400) & Loss 35.03047180175781\n",
            "Epochs(314/400) & Loss 34.96540069580078\n",
            "Epochs(315/400) & Loss 34.90047836303711\n",
            "Epochs(316/400) & Loss 34.83570098876953\n",
            "Epochs(317/400) & Loss 34.77104949951172\n",
            "Epochs(318/400) & Loss 34.70655059814453\n",
            "Epochs(319/400) & Loss 34.64215850830078\n",
            "Epochs(320/400) & Loss 34.5778923034668\n",
            "Epochs(321/400) & Loss 34.513771057128906\n",
            "Epochs(322/400) & Loss 34.449798583984375\n",
            "Epochs(323/400) & Loss 34.385902404785156\n",
            "Epochs(324/400) & Loss 34.32216262817383\n",
            "Epochs(325/400) & Loss 34.25851821899414\n",
            "Epochs(326/400) & Loss 34.195011138916016\n",
            "Epochs(327/400) & Loss 34.13166046142578\n",
            "Epochs(328/400) & Loss 34.068382263183594\n",
            "Epochs(329/400) & Loss 34.00525665283203\n",
            "Epochs(330/400) & Loss 33.942264556884766\n",
            "Epochs(331/400) & Loss 33.879398345947266\n",
            "Epochs(332/400) & Loss 33.81666946411133\n",
            "Epochs(333/400) & Loss 33.75402069091797\n",
            "Epochs(334/400) & Loss 33.69153594970703\n",
            "Epochs(335/400) & Loss 33.62910842895508\n",
            "Epochs(336/400) & Loss 33.566871643066406\n",
            "Epochs(337/400) & Loss 33.504737854003906\n",
            "Epochs(338/400) & Loss 33.44273376464844\n",
            "Epochs(339/400) & Loss 33.380828857421875\n",
            "Epochs(340/400) & Loss 33.319053649902344\n",
            "Epochs(341/400) & Loss 33.257415771484375\n",
            "Epochs(342/400) & Loss 33.19590377807617\n",
            "Epochs(343/400) & Loss 33.134498596191406\n",
            "Epochs(344/400) & Loss 33.07318878173828\n",
            "Epochs(345/400) & Loss 33.012020111083984\n",
            "Epochs(346/400) & Loss 32.950965881347656\n",
            "Epochs(347/400) & Loss 32.89003372192383\n",
            "Epochs(348/400) & Loss 32.829219818115234\n",
            "Epochs(349/400) & Loss 32.7685661315918\n",
            "Epochs(350/400) & Loss 32.70796203613281\n",
            "Epochs(351/400) & Loss 32.647518157958984\n",
            "Epochs(352/400) & Loss 32.587188720703125\n",
            "Epochs(353/400) & Loss 32.52698516845703\n",
            "Epochs(354/400) & Loss 32.46685028076172\n",
            "Epochs(355/400) & Loss 32.40691375732422\n",
            "Epochs(356/400) & Loss 32.346988677978516\n",
            "Epochs(357/400) & Loss 32.287269592285156\n",
            "Epochs(358/400) & Loss 32.22761535644531\n",
            "Epochs(359/400) & Loss 32.1680908203125\n",
            "Epochs(360/400) & Loss 32.10870361328125\n",
            "Epochs(361/400) & Loss 32.0494384765625\n",
            "Epochs(362/400) & Loss 31.9902400970459\n",
            "Epochs(363/400) & Loss 31.931232452392578\n",
            "Epochs(364/400) & Loss 31.872243881225586\n",
            "Epochs(365/400) & Loss 31.81338119506836\n",
            "Epochs(366/400) & Loss 31.75469970703125\n",
            "Epochs(367/400) & Loss 31.69608497619629\n",
            "Epochs(368/400) & Loss 31.63759422302246\n",
            "Epochs(369/400) & Loss 31.579233169555664\n",
            "Epochs(370/400) & Loss 31.520986557006836\n",
            "Epochs(371/400) & Loss 31.462879180908203\n",
            "Epochs(372/400) & Loss 31.40485191345215\n",
            "Epochs(373/400) & Loss 31.346832275390625\n",
            "Epochs(374/400) & Loss 31.289077758789062\n",
            "Epochs(375/400) & Loss 31.231372833251953\n",
            "Epochs(376/400) & Loss 31.173757553100586\n",
            "Epochs(377/400) & Loss 31.116296768188477\n",
            "Epochs(378/400) & Loss 31.058935165405273\n",
            "Epochs(379/400) & Loss 31.001684188842773\n",
            "Epochs(380/400) & Loss 30.944543838500977\n",
            "Epochs(381/400) & Loss 30.887493133544922\n",
            "Epochs(382/400) & Loss 30.83058738708496\n",
            "Epochs(383/400) & Loss 30.77372169494629\n",
            "Epochs(384/400) & Loss 30.7170352935791\n",
            "Epochs(385/400) & Loss 30.660480499267578\n",
            "Epochs(386/400) & Loss 30.603954315185547\n",
            "Epochs(387/400) & Loss 30.547616958618164\n",
            "Epochs(388/400) & Loss 30.491336822509766\n",
            "Epochs(389/400) & Loss 30.43515968322754\n",
            "Epochs(390/400) & Loss 30.379104614257812\n",
            "Epochs(391/400) & Loss 30.323169708251953\n",
            "Epochs(392/400) & Loss 30.2673397064209\n",
            "Epochs(393/400) & Loss 30.211597442626953\n",
            "Epochs(394/400) & Loss 30.155954360961914\n",
            "Epochs(395/400) & Loss 30.100439071655273\n",
            "Epochs(396/400) & Loss 30.045013427734375\n",
            "Epochs(397/400) & Loss 29.989742279052734\n",
            "Epochs(398/400) & Loss 29.934520721435547\n",
            "Epochs(399/400) & Loss 29.879409790039062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds=model(inputs)\n",
        "Loss = MSE(target,preds)\n",
        "print(Loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVtCbj98be28",
        "outputId": "07a50fd1-a485-4581-fdf3-9eda448caeb3"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(29.8245, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "sqrt(Loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_ZJOS5pb0U1",
        "outputId": "dc25cbf5-2a81-4ee6-ead9-dddb43fd3e01"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.461177269470302"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0YHF-jub3X-",
        "outputId": "d22657b3-e188-4576-cbbd-50f2c9babd15"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.9236,  70.5641],\n",
              "        [ 86.3279,  97.5390],\n",
              "        [109.7139, 139.6660],\n",
              "        [ 18.6017,  39.3299],\n",
              "        [110.8424, 112.1036]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xzs4ijeb6hP",
        "outputId": "e72a4ada-ba5e-4ded-8bba-07e472479e20"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    }
  ]
}